{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dummy variables\n",
    "Being able to include categorical features in the model building process can enhance performance as they may add information that contributes to prediction accuracy.\n",
    "\n",
    "The music_df dataset has been preloaded for you, and its shape is printed. Also, pandas has been imported as pd.\n",
    "\n",
    "Now you will create a new DataFrame containing the original columns of music_df plus dummy variables from the \"genre\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of music_dummies: (1000, 20)\n",
      "Index(['popularity', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
      "       'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo',\n",
      "       'valence', 'genre'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre_Anime</th>\n",
       "      <th>genre_Blues</th>\n",
       "      <th>genre_Classical</th>\n",
       "      <th>genre_Country</th>\n",
       "      <th>genre_Electronic</th>\n",
       "      <th>genre_Hip-Hop</th>\n",
       "      <th>genre_Jazz</th>\n",
       "      <th>genre_Rap</th>\n",
       "      <th>genre_Rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36506</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.726</td>\n",
       "      <td>214547.0</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>-14.824</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>92.934</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37591</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.635</td>\n",
       "      <td>190448.0</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>-4.795</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>110.012</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37658</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.352</td>\n",
       "      <td>456320.0</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>-3.634</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>122.897</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36060</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>352280.0</td>\n",
       "      <td>0.3260</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>-12.020</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>106.063</td>\n",
       "      <td>0.3230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35710</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>273693.0</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>-7.787</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>143.995</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44501</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.193</td>\n",
       "      <td>208040.0</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.929000</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>-28.228</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>82.165</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25114</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.939</td>\n",
       "      <td>144453.0</td>\n",
       "      <td>0.3730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>-7.779</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>119.953</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46896</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.739</td>\n",
       "      <td>238339.0</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>-9.735</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>85.082</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45135</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.515</td>\n",
       "      <td>286707.0</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>-5.606</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>150.063</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18960</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.291</td>\n",
       "      <td>194679.0</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>-6.972</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>146.245</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "36506        60.0      0.896000         0.726     214547.0  0.1770   \n",
       "37591        63.0      0.003840         0.635     190448.0  0.9080   \n",
       "37658        59.0      0.000075         0.352     456320.0  0.9560   \n",
       "36060        54.0      0.945000         0.488     352280.0  0.3260   \n",
       "35710        55.0      0.245000         0.667     273693.0  0.6470   \n",
       "...           ...           ...           ...          ...     ...   \n",
       "44501        57.0      0.972000         0.193     208040.0  0.0329   \n",
       "25114        56.0      0.005790         0.939     144453.0  0.3730   \n",
       "46896        54.0      0.016100         0.739     238339.0  0.5390   \n",
       "45135        62.0      0.326000         0.515     286707.0  0.5050   \n",
       "18960        42.0      0.029500         0.291     194679.0  0.5980   \n",
       "\n",
       "       instrumentalness  liveness  loudness  speechiness    tempo  valence  \\\n",
       "36506          0.000002    0.1160   -14.824       0.0353   92.934   0.6180   \n",
       "37591          0.083400    0.2390    -4.795       0.0563  110.012   0.6370   \n",
       "37658          0.020300    0.1250    -3.634       0.1490  122.897   0.2280   \n",
       "36060          0.015700    0.1190   -12.020       0.0328  106.063   0.3230   \n",
       "35710          0.000297    0.0633    -7.787       0.0487  143.995   0.3000   \n",
       "...                 ...       ...       ...          ...      ...      ...   \n",
       "44501          0.929000    0.0978   -28.228       0.0460   82.165   0.0366   \n",
       "25114          0.000000    0.2740    -7.779       0.2270  119.953   0.0602   \n",
       "46896          0.000000    0.2350    -9.735       0.3370   85.082   0.8350   \n",
       "45135          0.000000    0.1020    -5.606       0.0294  150.063   0.5380   \n",
       "18960          0.002270    0.0738    -6.972       0.0394  146.245   0.1860   \n",
       "\n",
       "       genre_Anime  genre_Blues  genre_Classical  genre_Country  \\\n",
       "36506            0            0                1              0   \n",
       "37591            0            0                0              0   \n",
       "37658            0            1                0              0   \n",
       "36060            1            0                0              0   \n",
       "35710            0            0                0              0   \n",
       "...            ...          ...              ...            ...   \n",
       "44501            0            0                1              0   \n",
       "25114            0            0                0              0   \n",
       "46896            0            1                0              0   \n",
       "45135            0            0                1              0   \n",
       "18960            0            0                0              0   \n",
       "\n",
       "       genre_Electronic  genre_Hip-Hop  genre_Jazz  genre_Rap  genre_Rock  \n",
       "36506                 0              0           0          0           0  \n",
       "37591                 0              0           0          0           1  \n",
       "37658                 0              0           0          0           0  \n",
       "36060                 0              0           0          0           0  \n",
       "35710                 0              0           0          0           0  \n",
       "...                 ...            ...         ...        ...         ...  \n",
       "44501                 0              0           0          0           0  \n",
       "25114                 0              0           0          1           0  \n",
       "46896                 0              0           0          0           0  \n",
       "45135                 0              0           0          0           0  \n",
       "18960                 1              0           0          0           0  \n",
       "\n",
       "[1000 rows x 20 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "music_df = pd.read_csv(\"music_clean.csv\")\n",
    "\n",
    "#datasette genre sadece 0 ve 1 lerden olustugu icin datacamptaki genreleri buraya alıp random atama yaptık.\n",
    "music_df['genre'] = pd.Series(\n",
    "    random.choices(['Blues', 'Rock', 'Classical', 'Anime', 'Alternative', 'Electronic', 'Country', 'Hip-Hop', 'Jazz', 'Rap'], weights=None, k=len(music_df)), \n",
    "    index=music_df.index)\n",
    "    \n",
    "\n",
    "# Create music_dummies\n",
    "music_dummies = pd.get_dummies(music_df, drop_first = True)\n",
    "\n",
    "# Print the new DataFrame's shape\n",
    "print(\"Shape of music_dummies: {}\".format(music_dummies.shape))\n",
    "print(music_df.columns)\n",
    "music_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there were ten values in the \"genre\" column, nine new columns were added by a call of pd.get_dummies() using drop_first=True. After dropping the original \"genre\" column, there are still eight new columns in the DataFrame!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression with categorical features\n",
    "Now you have created music_dummies, containing binary features for each song's genre, it's time to build a ridge regression model to predict song popularity.\n",
    "\n",
    "music_dummies has been preloaded for you, along with Ridge, cross_val_score, numpy as np, and a KFold object stored as kf.\n",
    "\n",
    "The model will be evaluated by calculating the average RMSE, but first, you will need to convert the scores for each fold to positive values and take their square root. This metric shows the average error of our model's predictions, so it can be compared against the standard deviation of the target value—\"popularity\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 12.583721898962715\n",
      "Standard Deviation of the target array: 14.02156909907019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state=42)\n",
    "\n",
    "# Create X and y\n",
    "X = music_dummies.drop(\"popularity\", axis = 1).values\n",
    "y = music_dummies[\"popularity\"].values\n",
    "\n",
    "# Instantiate a ridge model\n",
    "ridge = Ridge(alpha = 0.2)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(-scores)\n",
    "print(\"Average RMSE: {}\".format(np.mean(rmse)))\n",
    "print(\"Standard Deviation of the target array: {}\".format(np.std(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! An average RMSE of approximately 12.53 is lower than the standard deviation of the target variable (song popularity), suggesting the model is reasonably accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping missing data\n",
    "Over the next three exercises, you are going to tidy the music_df dataset. You will create a pipeline to impute missing values and build a KNN classifier model, then use it to predict whether a song is of the \"Rock\" genre.\n",
    "\n",
    "In this exercise specifically, you will drop missing values accounting for less than 5% of the dataset, and convert the \"genre\" column into a binary feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print missing values for each column\n",
    "print(music_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n",
      "Shape of the `music_df`: (1000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n",
    "\n",
    "# Convert genre to a binary feature\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "print(music_df.isna().sum().sort_values())\n",
    "print(\"Shape of the `music_df`: {}\".format(music_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! The dataset has gone from 1000 observations down to 892, but it is now in the correct format for binary classification and the remaining missing values can be imputed as part of a pipeline. (Bizim datasette zaten NaN olmadığı için 1000 olarak kaldı ama datacamptakinde NaN vardı.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Instantiate an imputer\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "# Instantiate a knn model\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "# Build steps for the pipeline\n",
    "steps = [(\"imputer\", imputer), \n",
    "         (\"knn\", knn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect pipeline skills! You are now ready to build and evaluate a song genre classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for song genre prediction: II\n",
    "Having set up the steps of the pipeline in the previous exercise, you will now use it on the music_df dataset to classify the genre of songs. What makes pipelines so incredibly useful is the simple interface that they provide.\n",
    "\n",
    "X_train, X_test, y_train, and y_test have been preloaded for you, and confusion_matrix has been imported from sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266   3]\n",
      " [ 29   2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X = music_df.drop(\"genre\", axis = 1).values\n",
    "y = music_df[\"genre\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# Build steps for the pipeline\n",
    "steps = [(\"imputer\", imputer), \n",
    "         (\"knn\", knn)]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! See how easy it is to scale our model building workflow using pipelines. In this case, the confusion matrix highlights that the model had 265 true positives and 1 true negatives!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centering and scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Centering and scaling for regression\n",
    "Now you have seen the benefits of scaling your data, you will use a pipeline to preprocess the music_df features and build a lasso regression model to predict a song's loudness.\n",
    "\n",
    "X_train, X_test, y_train, and y_test have been created from the music_df dataset, where the target is \"loudness\" and the features are all other columns in the dataset. Lasso and Pipeline have also been imported for you.\n",
    "\n",
    "Note that \"genre\" has been converted to a binary feature where 1 indicates a rock song, and 0 represents other genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7185052288252617\n"
     ]
    }
   ],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = music_df.drop(\"loudness\", axis = 1).values\n",
    "y = music_df[\"loudness\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# Create pipeline steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"lasso\", Lasso(alpha=0.5))]\n",
    "\n",
    "# Instantiate the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate and print R-squared\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome scaling! The model may have only produced an R-squared of 0.718, but without scaling this exact model would have only produced a score of 0.35, which proves just how powerful scaling can be!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Centering and scaling for classification\n",
    "Now you will bring together scaling and model building into a pipeline for cross-validation.\n",
    "\n",
    "Your task is to build a pipeline to scale features in the music_df dataset and perform grid search cross-validation using a logistic regression model with different values for the hyperparameter C. The target variable here is \"genre\", which contains binary values for rock as 1 and any other genre as 0.\n",
    "\n",
    "StandardScaler, LogisticRegression, and GridSearchCV have all been imported for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 \n",
      " {'logreg__C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = music_df.drop(\"genre\", axis = 1).values\n",
    "y = music_df[\"genre\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "\n",
    "# Build the steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"logreg\", LogisticRegression())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create the parameter space\n",
    "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "# Instantiate the grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! Using a pipeline shows that a logistic regression model with \"C\" set to 0.001 produces a model with 0.91 accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating multiple models\n",
    "#### Visualizing regression model performance\n",
    "Now you have seen how to evaluate multiple models out of the box, you will build three regression models to predict a song's \"energy\" levels.\n",
    "\n",
    "The music_df dataset has had dummy variables for \"genre\" added. Also, feature and target arrays have been created, and these have been split into X_train, X_test, y_train, and y_test.\n",
    "\n",
    "The following have been imported for you: LinearRegression, Ridge, Lasso, cross_val_score, and KFold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "\n",
    "X = music_df.drop(\"energy\", axis = 1).values\n",
    "y = music_df[\"energy\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "models = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "  \n",
    "  # Append the results\n",
    "  results.append(cv_scores)\n",
    "\n",
    "# Create a box plot of the results\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done! Lasso regression is not a good model for this problem, while linear regression and ridge perform fairly equally. Let's make predictions on the test set, and see if the RMSE can guide us on model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting on the test set\n",
    "In the last exercise, linear regression and ridge appeared to produce similar results. It would be appropriate to select either of those models; however, you can check predictive performance on the test set to see if either one can outperform the other.\n",
    "\n",
    "You will use root mean squared error (RMSE) as the metric. The dictionary models, containing the names and instances of the two models, has been preloaded for you along with the training and target arrays X_train_scaled, X_test_scaled, y_train, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Test Set RMSE: 0.11064650358738104\n",
      "Ridge Test Set RMSE: 0.11064903843065729\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = music_df.drop(\"energy\", axis = 1).values\n",
    "y = music_df[\"energy\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "models = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1)}\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "  \n",
    "  # Fit the model to the training data\n",
    "  model.fit(X_train_scaled, y_train)\n",
    "  \n",
    "  # Make predictions on the test set\n",
    "  y_pred = model.predict(X_test_scaled)\n",
    "  \n",
    "  # Calculate the test_rmse\n",
    "  test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "  print(\"{} Test Set RMSE: {}\".format(name, test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression model just edges the best performance, although the difference is a RMSE of 0.00001 for popularity! Now let's look at classification model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing classification model performance\n",
    "In this exercise, you will be solving a classification problem where the \"popularity\" column in the music_df dataset has been converted to binary values, with 1 representing popularity more than or equal to the median for the \"popularity\" column, and 0 indicating popularity below the median.\n",
    "\n",
    "Your task is to build and visualize the results of three different models to classify whether a song is popular or not.\n",
    "\n",
    "The data has been split, scaled, and preloaded for you as X_train_scaled, X_test_scaled, y_train, and y_test. Additionally, KNeighborsClassifier, DecisionTreeClassifier, and LogisticRegression have been imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "music_df[\"popularity\"] = np.where(music_df[\"popularity\"]  >= np.median(music_df[\"popularity\"]), 1, 0)\n",
    "\n",
    "X = music_df.drop(\"popularity\", axis = 1).values\n",
    "y = music_df[\"popularity\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create models dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \"KNN\": KNeighborsClassifier(), \"Decision Tree Classifier\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  \n",
    "  # Instantiate a KFold object\n",
    "  kf = KFold(n_splits=6, random_state=12, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "  results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like logistic regression is the best candidate based on the cross-validation results! Let's wrap up by building a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for predicting song popularity\n",
    "For the final exercise, you will build a pipeline to impute missing values, scale features, and perform hyperparameter tuning of a logistic regression model. The aim is to find the best parameters and accuracy when predicting song genre!\n",
    "\n",
    "All the models and objects required to build the pipeline have been preloaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'logreg__C': 0.112, 'logreg__solver': 'newton-cg'}, Accuracy: 0.59\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create steps\n",
    "steps = [(\"imp_mean\", SimpleImputer()), \n",
    "         (\"scaler\", StandardScaler()), \n",
    "         (\"logreg\", LogisticRegression())]\n",
    "\n",
    "# Set up pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "params = {\"logreg__solver\": [\"newton-cg\", \"saga\", \"lbfgs\"],\n",
    "         \"logreg__C\": np.linspace(0.001, 1.0, 10)}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "tuning = GridSearchCV(pipeline, param_grid=params)\n",
    "tuning.fit(X_train, y_train)\n",
    "y_pred = tuning.predict(X_test)\n",
    "\n",
    "# Compute and print performance\n",
    "print(\"Tuned Logistic Regression Parameters: {}, Accuracy: {}\".format(tuning.best_params_, tuning.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent - you've selected a model, built a preprocessing pipeline, and performed hyperparameter tuning to create a model that is 82% accurate in predicting song genres!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
