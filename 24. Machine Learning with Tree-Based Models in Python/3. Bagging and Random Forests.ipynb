{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging is an ensemble method involving training the same algorithm many times using different subsets sampled from the training data. In this chapter, you'll understand how bagging can be used to create a tree ensemble. You'll also learn how the random forests algorithm can lead to further ensemble diversity through randomization at the level of each split in the trees forming the ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "#### Define the bagging classifier\n",
    "In the following exercises you'll work with the Indian Liver Patient dataset from the UCI machine learning repository. Your task is to predict whether a patient suffers from a liver disease using 10 features including Albumin, age and gender. You'll do so using a Bagging Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age_std</th>\n",
       "      <th>Total_Bilirubin_std</th>\n",
       "      <th>Direct_Bilirubin_std</th>\n",
       "      <th>Alkaline_Phosphotase_std</th>\n",
       "      <th>Alamine_Aminotransferase_std</th>\n",
       "      <th>Aspartate_Aminotransferase_std</th>\n",
       "      <th>Total_Protiens_std</th>\n",
       "      <th>Albumin_std</th>\n",
       "      <th>Albumin_and_Globulin_Ratio_std</th>\n",
       "      <th>Is_male_std</th>\n",
       "      <th>Liver_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.247403</td>\n",
       "      <td>-0.420320</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>-0.355832</td>\n",
       "      <td>-0.319111</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.062306</td>\n",
       "      <td>1.218936</td>\n",
       "      <td>1.423518</td>\n",
       "      <td>1.675083</td>\n",
       "      <td>-0.093573</td>\n",
       "      <td>-0.035962</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>-0.648461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.062306</td>\n",
       "      <td>0.640375</td>\n",
       "      <td>0.926017</td>\n",
       "      <td>0.816243</td>\n",
       "      <td>-0.115428</td>\n",
       "      <td>-0.146459</td>\n",
       "      <td>0.478274</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.178707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.815511</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.388807</td>\n",
       "      <td>-0.449416</td>\n",
       "      <td>-0.366760</td>\n",
       "      <td>-0.312205</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.679294</td>\n",
       "      <td>0.093956</td>\n",
       "      <td>0.179766</td>\n",
       "      <td>-0.395996</td>\n",
       "      <td>-0.295731</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>-0.930414</td>\n",
       "      <td>-1.713237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>578</td>\n",
       "      <td>0.938909</td>\n",
       "      <td>-0.452462</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>0.857336</td>\n",
       "      <td>-0.333977</td>\n",
       "      <td>-0.263863</td>\n",
       "      <td>-0.536763</td>\n",
       "      <td>-1.938290</td>\n",
       "      <td>-1.807188</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>579</td>\n",
       "      <td>-0.295067</td>\n",
       "      <td>-0.436391</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>-0.794596</td>\n",
       "      <td>-0.252021</td>\n",
       "      <td>-0.274222</td>\n",
       "      <td>-0.444487</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>0.478949</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>580</td>\n",
       "      <td>0.445318</td>\n",
       "      <td>-0.404249</td>\n",
       "      <td>-0.459878</td>\n",
       "      <td>-0.190532</td>\n",
       "      <td>-0.180993</td>\n",
       "      <td>-0.212067</td>\n",
       "      <td>-0.075383</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>581</td>\n",
       "      <td>-0.850356</td>\n",
       "      <td>-0.323893</td>\n",
       "      <td>-0.353271</td>\n",
       "      <td>-0.441198</td>\n",
       "      <td>-0.284804</td>\n",
       "      <td>-0.270769</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>582</td>\n",
       "      <td>-0.418465</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.424343</td>\n",
       "      <td>-0.309701</td>\n",
       "      <td>-0.328514</td>\n",
       "      <td>-0.298393</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>1.589276</td>\n",
       "      <td>1.731627</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>579 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   Age_std  Total_Bilirubin_std  Direct_Bilirubin_std  \\\n",
       "0             0  1.247403            -0.420320             -0.495414   \n",
       "1             1  1.062306             1.218936              1.423518   \n",
       "2             2  1.062306             0.640375              0.926017   \n",
       "3             3  0.815511            -0.372106             -0.388807   \n",
       "4             4  1.679294             0.093956              0.179766   \n",
       "..          ...       ...                  ...                   ...   \n",
       "574         578  0.938909            -0.452462             -0.495414   \n",
       "575         579 -0.295067            -0.436391             -0.495414   \n",
       "576         580  0.445318            -0.404249             -0.459878   \n",
       "577         581 -0.850356            -0.323893             -0.353271   \n",
       "578         582 -0.418465            -0.372106             -0.424343   \n",
       "\n",
       "     Alkaline_Phosphotase_std  Alamine_Aminotransferase_std  \\\n",
       "0                   -0.428870                     -0.355832   \n",
       "1                    1.675083                     -0.093573   \n",
       "2                    0.816243                     -0.115428   \n",
       "3                   -0.449416                     -0.366760   \n",
       "4                   -0.395996                     -0.295731   \n",
       "..                        ...                           ...   \n",
       "574                  0.857336                     -0.333977   \n",
       "575                 -0.794596                     -0.252021   \n",
       "576                 -0.190532                     -0.180993   \n",
       "577                 -0.441198                     -0.284804   \n",
       "578                 -0.309701                     -0.328514   \n",
       "\n",
       "     Aspartate_Aminotransferase_std  Total_Protiens_std  Albumin_std  \\\n",
       "0                         -0.319111            0.293722     0.203446   \n",
       "1                         -0.035962            0.939655     0.077462   \n",
       "2                         -0.146459            0.478274     0.203446   \n",
       "3                         -0.312205            0.293722     0.329431   \n",
       "4                         -0.177537            0.755102    -0.930414   \n",
       "..                              ...                 ...          ...   \n",
       "574                       -0.263863           -0.536763    -1.938290   \n",
       "575                       -0.274222           -0.444487     0.077462   \n",
       "576                       -0.212067           -0.075383     0.077462   \n",
       "577                       -0.270769            0.293722     0.329431   \n",
       "578                       -0.298393            0.755102     1.589276   \n",
       "\n",
       "     Albumin_and_Globulin_Ratio_std  Is_male_std  Liver_disease  \n",
       "0                         -0.147390            0              1  \n",
       "1                         -0.648461            1              1  \n",
       "2                         -0.178707            1              1  \n",
       "3                          0.165780            1              1  \n",
       "4                         -1.713237            1              1  \n",
       "..                              ...          ...            ...  \n",
       "574                       -1.807188            1              0  \n",
       "575                        0.478949            1              1  \n",
       "576                        0.165780            1              1  \n",
       "577                        0.165780            1              1  \n",
       "578                        1.731627            1              0  \n",
       "\n",
       "[579 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "indian_liver = pd.read_csv('indian_liver_patient_preprocessed.csv')\n",
    "indian_liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_std</th>\n",
       "      <th>Total_Bilirubin_std</th>\n",
       "      <th>Direct_Bilirubin_std</th>\n",
       "      <th>Alkaline_Phosphotase_std</th>\n",
       "      <th>Alamine_Aminotransferase_std</th>\n",
       "      <th>Aspartate_Aminotransferase_std</th>\n",
       "      <th>Total_Protiens_std</th>\n",
       "      <th>Albumin_std</th>\n",
       "      <th>Albumin_and_Globulin_Ratio_std</th>\n",
       "      <th>Is_male_std</th>\n",
       "      <th>Liver_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.247403</td>\n",
       "      <td>-0.420320</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>-0.355832</td>\n",
       "      <td>-0.319111</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>1.218936</td>\n",
       "      <td>1.423518</td>\n",
       "      <td>1.675083</td>\n",
       "      <td>-0.093573</td>\n",
       "      <td>-0.035962</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>-0.648461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>0.640375</td>\n",
       "      <td>0.926017</td>\n",
       "      <td>0.816243</td>\n",
       "      <td>-0.115428</td>\n",
       "      <td>-0.146459</td>\n",
       "      <td>0.478274</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.178707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815511</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.388807</td>\n",
       "      <td>-0.449416</td>\n",
       "      <td>-0.366760</td>\n",
       "      <td>-0.312205</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.679294</td>\n",
       "      <td>0.093956</td>\n",
       "      <td>0.179766</td>\n",
       "      <td>-0.395996</td>\n",
       "      <td>-0.295731</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>-0.930414</td>\n",
       "      <td>-1.713237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0.938909</td>\n",
       "      <td>-0.452462</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>0.857336</td>\n",
       "      <td>-0.333977</td>\n",
       "      <td>-0.263863</td>\n",
       "      <td>-0.536763</td>\n",
       "      <td>-1.938290</td>\n",
       "      <td>-1.807188</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>-0.295067</td>\n",
       "      <td>-0.436391</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>-0.794596</td>\n",
       "      <td>-0.252021</td>\n",
       "      <td>-0.274222</td>\n",
       "      <td>-0.444487</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>0.478949</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0.445318</td>\n",
       "      <td>-0.404249</td>\n",
       "      <td>-0.459878</td>\n",
       "      <td>-0.190532</td>\n",
       "      <td>-0.180993</td>\n",
       "      <td>-0.212067</td>\n",
       "      <td>-0.075383</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>-0.850356</td>\n",
       "      <td>-0.323893</td>\n",
       "      <td>-0.353271</td>\n",
       "      <td>-0.441198</td>\n",
       "      <td>-0.284804</td>\n",
       "      <td>-0.270769</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>-0.418465</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.424343</td>\n",
       "      <td>-0.309701</td>\n",
       "      <td>-0.328514</td>\n",
       "      <td>-0.298393</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>1.589276</td>\n",
       "      <td>1.731627</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>579 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age_std  Total_Bilirubin_std  Direct_Bilirubin_std  \\\n",
       "0    1.247403            -0.420320             -0.495414   \n",
       "1    1.062306             1.218936              1.423518   \n",
       "2    1.062306             0.640375              0.926017   \n",
       "3    0.815511            -0.372106             -0.388807   \n",
       "4    1.679294             0.093956              0.179766   \n",
       "..        ...                  ...                   ...   \n",
       "574  0.938909            -0.452462             -0.495414   \n",
       "575 -0.295067            -0.436391             -0.495414   \n",
       "576  0.445318            -0.404249             -0.459878   \n",
       "577 -0.850356            -0.323893             -0.353271   \n",
       "578 -0.418465            -0.372106             -0.424343   \n",
       "\n",
       "     Alkaline_Phosphotase_std  Alamine_Aminotransferase_std  \\\n",
       "0                   -0.428870                     -0.355832   \n",
       "1                    1.675083                     -0.093573   \n",
       "2                    0.816243                     -0.115428   \n",
       "3                   -0.449416                     -0.366760   \n",
       "4                   -0.395996                     -0.295731   \n",
       "..                        ...                           ...   \n",
       "574                  0.857336                     -0.333977   \n",
       "575                 -0.794596                     -0.252021   \n",
       "576                 -0.190532                     -0.180993   \n",
       "577                 -0.441198                     -0.284804   \n",
       "578                 -0.309701                     -0.328514   \n",
       "\n",
       "     Aspartate_Aminotransferase_std  Total_Protiens_std  Albumin_std  \\\n",
       "0                         -0.319111            0.293722     0.203446   \n",
       "1                         -0.035962            0.939655     0.077462   \n",
       "2                         -0.146459            0.478274     0.203446   \n",
       "3                         -0.312205            0.293722     0.329431   \n",
       "4                         -0.177537            0.755102    -0.930414   \n",
       "..                              ...                 ...          ...   \n",
       "574                       -0.263863           -0.536763    -1.938290   \n",
       "575                       -0.274222           -0.444487     0.077462   \n",
       "576                       -0.212067           -0.075383     0.077462   \n",
       "577                       -0.270769            0.293722     0.329431   \n",
       "578                       -0.298393            0.755102     1.589276   \n",
       "\n",
       "     Albumin_and_Globulin_Ratio_std  Is_male_std  Liver_disease  \n",
       "0                         -0.147390            0              1  \n",
       "1                         -0.648461            1              1  \n",
       "2                         -0.178707            1              1  \n",
       "3                          0.165780            1              1  \n",
       "4                         -1.713237            1              1  \n",
       "..                              ...          ...            ...  \n",
       "574                       -1.807188            1              0  \n",
       "575                        0.478949            1              1  \n",
       "576                        0.165780            1              1  \n",
       "577                        0.165780            1              1  \n",
       "578                        1.731627            1              0  \n",
       "\n",
       "[579 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indian_liver = indian_liver.drop(columns = 'Unnamed: 0') # = indian_liver.drop(columns='Unnamed: 0', inplace=True)\n",
    "indian_liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier and BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1) # Instantiate a BaggingClassifier \n",
    "                                                                           #called bc consisting of 50 trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! In the following exercise, you'll train bc and evaluate its test set performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Bagging performance\n",
    "Now that you instantiated the bagging classifier, it's time to train it and evaluate its test set accuracy.\n",
    "\n",
    "The Indian Liver Patient dataset is processed for you and split into 80% train and 20% test. The feature matrices X_train and X_test, as well as the arrays of labels y_train and y_test are available in your workspace. In addition, we have also loaded the bagging classifier bc that you instantiated in the previous exercise and the function accuracy_score() from sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = indian_liver.iloc[:,:-1]\n",
    "y = indian_liver.iloc[:,-1]\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = SEED)\n",
    "    \n",
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of Bag Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the ground\n",
    "In the following exercises, you'll compare the OOB accuracy to the test set accuracy of a bagging classifier trained on the Indian Liver Patient dataset.\n",
    "\n",
    "In sklearn, you can evaluate the OOB accuracy of an ensemble classifier by setting the parameter oob_score to True during instantiation. After training the classifier, the OOB accuracy can be obtained by accessing the .oob_score_ attribute from the corresponding instance.\n",
    "\n",
    "In your environment, we have made available the class DecisionTreeClassifier from sklearn.tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=8, random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, \n",
    "            n_estimators=50,\n",
    "            oob_score=True,\n",
    "            random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! In the following exercise, you'll train bc and compare its test set accuracy to its OOB accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OOB Score vs Test Set Score\n",
    "Now that you instantiated bc, you will fit it to the training set and evaluate its test set and OOB accuracies.\n",
    "\n",
    "The dataset is processed for you and split into 80% train and 20% test. The feature matrices X_train and X_test, as well as the arrays of labels y_train and y_test are available in your workspace. In addition, we have also loaded the classifier bc instantiated in the previous exercise and the function accuracy_score() from sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.698, OOB accuracy: 0.702\n"
     ]
    }
   ],
   "source": [
    "# Fit bc to the training set \n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate test set accuracy\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "\n",
    "# Evaluate OOB accuracy\n",
    "acc_oob = bc.oob_score_\n",
    "\n",
    "# Print acc_test and acc_oob\n",
    "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! The test set accuracy and the OOB accuracy of bc are both roughly equal to 70%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests (RF)\n",
    "#### Train an RF regressor\n",
    "In the following exercises you'll predict bike rental demand in the Capital Bikeshare program in Washington, D.C using historical weather data from the Bike Sharing Demand dataset available through Kaggle. For this purpose, you will be using the random forests algorithm. As a first step, you'll define a random forests regressor and fit it to the training set.\n",
    "\n",
    "The dataset is processed for you and split into 80% train and 20% test. The features matrix X_train and the array y_train are available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>instant</th>\n",
       "      <th>mnth</th>\n",
       "      <th>yr</th>\n",
       "      <th>Clear to partly cloudy</th>\n",
       "      <th>Light Precipitation</th>\n",
       "      <th>Misty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>149</td>\n",
       "      <td>13004</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>93</td>\n",
       "      <td>13005</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>90</td>\n",
       "      <td>13006</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>33</td>\n",
       "      <td>13007</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>4</td>\n",
       "      <td>13008</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>452</td>\n",
       "      <td>14487</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>356</td>\n",
       "      <td>14488</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>303</td>\n",
       "      <td>14489</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>277</td>\n",
       "      <td>14490</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>174</td>\n",
       "      <td>14491</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1488 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hr  holiday  workingday  temp   hum  windspeed  cnt  instant  mnth  yr  \\\n",
       "0      0        0           0  0.76  0.66     0.0000  149    13004     7   1   \n",
       "1      1        0           0  0.74  0.70     0.1343   93    13005     7   1   \n",
       "2      2        0           0  0.72  0.74     0.0896   90    13006     7   1   \n",
       "3      3        0           0  0.72  0.84     0.1343   33    13007     7   1   \n",
       "4      4        0           0  0.70  0.79     0.1940    4    13008     7   1   \n",
       "...   ..      ...         ...   ...   ...        ...  ...      ...   ...  ..   \n",
       "1483  19        0           1  0.80  0.49     0.1343  452    14487     8   1   \n",
       "1484  20        0           1  0.80  0.49     0.1343  356    14488     8   1   \n",
       "1485  21        0           1  0.76  0.58     0.1940  303    14489     8   1   \n",
       "1486  22        0           1  0.76  0.58     0.1940  277    14490     8   1   \n",
       "1487  23        0           1  0.74  0.62     0.1045  174    14491     8   1   \n",
       "\n",
       "      Clear to partly cloudy  Light Precipitation  Misty  \n",
       "0                          1                    0      0  \n",
       "1                          1                    0      0  \n",
       "2                          1                    0      0  \n",
       "3                          1                    0      0  \n",
       "4                          1                    0      0  \n",
       "...                      ...                  ...    ...  \n",
       "1483                       1                    0      0  \n",
       "1484                       1                    0      0  \n",
       "1485                       1                    0      0  \n",
       "1486                       1                    0      0  \n",
       "1487                       1                    0      0  \n",
       "\n",
       "[1488 rows x 13 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "bikes = pd.read_csv('bikes.TXT')\n",
    "bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=25, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=25, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=25, random_state=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = bikes.iloc[:, :6].join(bikes.iloc[:, 7:])\n",
    "y = bikes.iloc[:, 6]\n",
    "\n",
    "SEED = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = SEED)\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestRegressor(n_estimators=25,\n",
    "            random_state=SEED)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! Next comes the test set RMSE evaluation part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the RF regressor\n",
    "You'll now evaluate the test set RMSE of the random forests regressor rf that you trained in the previous exercise.\n",
    "\n",
    "The dataset is processed for you and split into 80% train and 20% test. The features matrix X_test, as well as the array y_test are available in your workspace. In addition, we have also loaded the model rf that you trained in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 52.38\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! You can try training a single CART on the same dataset. The test set RMSE achieved by rf is significantly smaller than that achieved by a single CART!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing features importances\n",
    "In this exercise, you'll determine which features were the most predictive according to the random forests regressor rf that you trained in a previous exercise.\n",
    "\n",
    "For this purpose, you'll draw a horizontal barplot of the feature importance as assessed by rf. Fortunately, this can be done easily thanks to plotting capabilities of pandas.\n",
    "\n",
    "We have created a pandas.Series object called importances containing the feature names as index and their importances as values. In addition, matplotlib.pyplot is available as plt and pandas as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf.feature_importances_,\n",
    "                        index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, hr and workingday are the most important features according to rf. The importances of these two features add up to more than 90%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
